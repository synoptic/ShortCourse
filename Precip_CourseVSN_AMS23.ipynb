{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Working with raw precipitation versus Synoptic's derived precipitation product\n",
        "\n",
        "Here's an example that illustrates some of the challenges of working with real time precipitation data from stations across many different networks."
      ],
      "metadata": {
        "id": "oBZHW9IZmjc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First the basics\n",
        "import urllib.request as req\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "%matplotlib inline\n",
        "\n",
        "def return_station_df(data, service):\n",
        "    \"\"\"Build pandas dataframes for data and metadata using json response from \n",
        "        requests to Time Series, Nearest, and Latest services\n",
        "\n",
        "    Parameters:\n",
        "        data: dict, json response from API request\n",
        "        service: str, Synoptic web service requested\n",
        "    \n",
        "    Returns:\n",
        "        data_df: pandas DataFrame, data return from all station\n",
        "        meta_df: pandas DataFrame, station metadata\n",
        "    \"\"\"\n",
        "    dattim_format = '%Y-%m-%d %H:%M'\n",
        "    meta_list = []\n",
        "    # We iterate over the list of stations\n",
        "    for i in range(len(data)):\n",
        "        # Append station metadata to a grand list that we'll convert to a df\n",
        "        stid = data[i]['STID']\n",
        "        mnet_id = data[i]['MNET_ID']\n",
        "        try:\n",
        "            lon = float(data[i]['LONGITUDE'])\n",
        "        except TypeError:\n",
        "            lon = None\n",
        "        try:\n",
        "            lat = float(data[i]['LATITUDE'])\n",
        "        except TypeError:\n",
        "            lat = None\n",
        "        try:\n",
        "            elev = float(data[i]['ELEVATION'])\n",
        "        except TypeError:\n",
        "            elev = None\n",
        "        meta_list.append([stid, mnet_id, lon, lat, elev])\n",
        "\n",
        "        # Create a multi-index object to attach to the data df\n",
        "        data_out = data[i]['OBSERVATIONS'].copy()\n",
        "        if service == 'timeseries':\n",
        "            datetime = pd.to_datetime(data_out['date_time'], format=(dattim_format))\n",
        "            del data_out['date_time']\n",
        "            multi_index = pd.MultiIndex.from_product([[stid], datetime],\n",
        "                                                     names=[\"stid\", \"dattim\"])\n",
        "        else:\n",
        "            datetime = pd.to_datetime(data_out[list(data_out.keys())[0]]['date_time'], format=(dattim_format))\n",
        "            for key in data_out:\n",
        "                data_out.update({key: data_out[key]['value']})\n",
        "            multi_index = pd.MultiIndex.from_arrays([[stid], [datetime]],\n",
        "                                                    names=[\"stid\", \"dattim\"])\n",
        "\n",
        "        # Build the data df, concatenating as needed\n",
        "        if i == 0:\n",
        "            data_df = pd.DataFrame(data_out, index=multi_index)\n",
        "        else:\n",
        "            data_df = pd.concat([data_df, pd.DataFrame(data_out, index=multi_index)], axis=0)\n",
        "\n",
        "    #Build metadata dataframe from list\n",
        "    meta_df = pd.DataFrame(meta_list, columns=[\"stid\", \"mnet_id\", \"lon\", \"lat\", \"elev\"])\n",
        "    meta_df.set_index('stid', inplace=True)\n",
        "\n",
        "    # Sort the resulting data dataframe by time\n",
        "    data_df.sort_index(inplace=True)\n",
        "\n",
        "    return data_df, meta_df"
      ],
      "metadata": {
        "id": "iszbbteSnSsy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_api_request(url, api_args):\n",
        "    \"\"\"Build the api request from the url and api_args, make the request, and parse \n",
        "    the json return to a dictionary\n",
        "\n",
        "    Parameters:\n",
        "        url: str, url of the api endpoint\n",
        "        api_args: dict, api arguments\n",
        "    \n",
        "    Returns:\n",
        "        output: dict, api request response \n",
        "    \"\"\"\n",
        "    # Append the api arguments on to the url\n",
        "    for argument, value in api_args.items():\n",
        "        url = url + '&' + argument + '=' + value\n",
        "\n",
        "    # Make the api request\n",
        "    print(f\"API request: {url}\")\n",
        "    with req.urlopen(url) as response:\n",
        "        body = response.read()\n",
        "\n",
        "    # parse the json response. \n",
        "    try:\n",
        "        output = json.loads(body)\n",
        "    except:\n",
        "        decoded_body = body.decode('latin1')\n",
        "        output = json.loads(decoded_body)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "izLr6-Z9nddg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example case: Missoula, MT\n",
        "\n",
        "For this example we'll focus on a wet weekend in Missoula, MT back in June. Let's request data from all the stations in Missoula County."
      ],
      "metadata": {
        "id": "Nu6jyFJ5nHCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1n_2s-1rmYAm"
      },
      "outputs": [],
      "source": [
        "token = ''\n",
        "url = 'https://api.synopticdata.com/v2/stations/timeseries?'\n",
        "api_args = {'state': 'mt',\n",
        "            'county': 'missoula',\n",
        "            'start': '202206100000',\n",
        "            'end': '202206130000',\n",
        "            'obtimezone': 'local',\n",
        "            'token': token}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = make_api_request(url, api_args)\n",
        "data['SUMMARY']"
      ],
      "metadata": {
        "id": "YsqYlzaroSm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The challenge: stations can report precipitation in a number of different formats\n",
        "\n",
        "Let's see how many different precip variables are returned by inspecting the `UNITS` dictionary"
      ],
      "metadata": {
        "id": "SO1ywa4soeZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['UNITS']"
      ],
      "metadata": {
        "id": "aAItN1tDoaDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create our data and metadata dataframes and explore in more detail the stations reporting different precip variable types"
      ],
      "metadata": {
        "id": "jEBFHNjZjEB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df, meta_df = return_station_df(data['STATION'], 'timeseries')"
      ],
      "metadata": {
        "id": "-HG3efnBo96R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a dataframe with stations reporting `precip_accum` values"
      ],
      "metadata": {
        "id": "dI5tM6lPpWgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precip_accum_df = data_df['precip_accum_set_1'].dropna()\n",
        "precip_accum_df\n"
      ],
      "metadata": {
        "id": "ngDGdfc7pBMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And a dataframe with stations reporting `precip_accum_since_local_midnight`"
      ],
      "metadata": {
        "id": "nzg5RgOipcYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precip_mid_df = data_df['precip_accum_since_local_midnight_set_1'].dropna()\n",
        "precip_mid_df\n"
      ],
      "metadata": {
        "id": "cnGs00jRpU6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And one more data frame with stations reporting `precip_accum_one_hour`:"
      ],
      "metadata": {
        "id": "jd9AEsRKp05h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precip_1hr_df = data_df['precip_accum_one_hour_set_1'].dropna()\n",
        "precip_1hr_df"
      ],
      "metadata": {
        "id": "uIDs5cXqqK7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can demonstrate the challenges of working with precip by plotting timeseries from a station reporting one of each of these values"
      ],
      "metadata": {
        "id": "AT5g8BIjmir2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.figure(1,figsize=(8,16))\n",
        "ax1a = fig1.add_subplot(311)\n",
        "ax1a.plot(precip_accum_df.loc['BLMM8'].index, precip_accum_df.loc['BLMM8'])\n",
        "ax1a.set_title('BLMM8')\n",
        "\n",
        "ax1b = fig1.add_subplot(312)\n",
        "ax1b.plot(precip_mid_df.loc['C4884'].index, precip_mid_df.loc['C4884'])\n",
        "ax1b.set_title('C4884')\n",
        "\n",
        "ax1c = fig1.add_subplot(313)\n",
        "ax1c.plot(precip_1hr_df.loc['KMSO'].index, precip_1hr_df.loc['KMSO'])\n",
        "ax1c.set_title('KMSO')"
      ],
      "metadata": {
        "id": "Ue0NLGDIqhEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One solution: derived precipitation\n",
        "\n",
        "Synoptic processes precipitation observations in real time, building a derived precipitation product that collapses different precipitation reporting into a consistent format. The derived precipitation product is accessed from the Timeseries endpoint by setting the `precip` argument."
      ],
      "metadata": {
        "id": "gci4lzujrgBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://api.synopticdata.com/v2/stations/timeseries?'\n",
        "api_args2 = {'stid': 'KMSO,C4884,BLMM8',\n",
        "            'start': '202206100000',\n",
        "            'end': '202206130000',\n",
        "            'obtimezone': 'local',\n",
        "            'precip':'1',\n",
        "            'token': token}"
      ],
      "metadata": {
        "id": "HWzz7HYwrmJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = make_api_request(url, api_args2)\n",
        "data2['SUMMARY']"
      ],
      "metadata": {
        "id": "30t75k1sr0HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['UNITS']"
      ],
      "metadata": {
        "id": "UFW-qamPr0yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df2, meta_df2 = return_station_df(data2['STATION'], 'timeseries')"
      ],
      "metadata": {
        "id": "sYAJdRw8sM1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df2.columns"
      ],
      "metadata": {
        "id": "gcNSSuu7ssCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot up the resulting precip accumulations"
      ],
      "metadata": {
        "id": "bcwgTM-4iLF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = plt.figure(2,figsize=(8,16))\n",
        "ax2a = fig2.add_subplot(311)\n",
        "ax2a.plot(data_df2.loc['BLMM8'].index, data_df2.loc['BLMM8','precip_accumulated_set_1d'])\n",
        "ax2a.set_title('BLMM8')\n",
        "\n",
        "ax2b = fig2.add_subplot(312)\n",
        "ax2b.plot(data_df2.loc['C4884'].index, data_df2.loc['C4884','precip_accumulated_set_1d'])\n",
        "ax2b.set_title('C4884')\n",
        "\n",
        "ax2c = fig2.add_subplot(313)\n",
        "ax2c.plot(data_df2.loc['KMSO'].index, data_df2.loc['KMSO','precip_accumulated_set_1d'])\n",
        "ax2c.set_title('KMSO')"
      ],
      "metadata": {
        "id": "URP9TRqOr4FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite the different reporting formats among the 3 stations, the measured precipitation shows a similar pattern over the weekend."
      ],
      "metadata": {
        "id": "B_uRLlEkiW-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Pick a handful of stations around CA from the recent Atmospheric River Events and plot up a time series of derived precipitation. How much precip has fallen? How much variability is there between stations?"
      ],
      "metadata": {
        "id": "PMoneOgfUjtf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plZ7ioRkUz74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}