{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKkA1c3L7OqM"
      },
      "source": [
        "# Introduction: Thomas Fire. Began December 4, 2017. Fueled by Santa Ana winds.\n",
        "The Thomas Fire began December 4, 2017 near the town of Santa Paula (34.4267,-119.1592). It grew into what, at the time, was California's largest fire in modern history. Let's use the API to explore the weather conditions in the days around the start of the fire that contributed to it's growth. \n",
        "\n",
        "## Q1: What were the winds like in the days leading up to the fire? How sustained were they?\n",
        "\n",
        "## Q2: How did the wind, relative humidity, and temperature interact in ways that might have affected fire weather conditions?\n",
        "\n",
        "## Q3: Were these conditions unprecedented over the last month?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhv7Ignk0VBf"
      },
      "source": [
        "# Step 0: Importing and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKEr2GbGqtqd"
      },
      "outputs": [],
      "source": [
        "import urllib.request as req\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwkprG010pdV"
      },
      "source": [
        "We've built a couple of functions to help in building the API request and parsing the returned data. These use the Pandas python package and builds a DataFrame using with two indices: station id and dattim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZkWP42MvNeR"
      },
      "outputs": [],
      "source": [
        "def return_station_df(data, service):\n",
        "    \"\"\"Build pandas dataframes for data and metadata using json response from \n",
        "        requests to Time Series, Nearest, and Latest services\n",
        "\n",
        "    Parameters:\n",
        "        data: dict, json response from API request\n",
        "        date_format: str, requested date format\n",
        "        service: str, Synoptic web service requested\n",
        "    \n",
        "    Returns:\n",
        "        data_df: pandas DataFrame, data return from all station\n",
        "        meta_df: pandas DataFrame, station metadata\n",
        "    \"\"\"\n",
        "    dattim_format = '%Y-%m-%d %H:%M'\n",
        "    meta_list = []\n",
        "    for i in range(len(data)):\n",
        "        # Metadata\n",
        "        stid = data[i]['STID']\n",
        "        mnet_id = data[i]['MNET_ID']\n",
        "        try:\n",
        "            lon = float(data[i]['LONGITUDE'])\n",
        "        except TypeError:\n",
        "            lon = None\n",
        "        try:\n",
        "            lat = float(data[i]['LATITUDE'])\n",
        "        except TypeError:\n",
        "            lat = None\n",
        "        try:\n",
        "            elev = float(data[i]['ELEVATION'])\n",
        "        except TypeError:\n",
        "            elev = None\n",
        "        meta_list.append([stid, mnet_id, lon, lat, elev])\n",
        "\n",
        "        # Data\n",
        "        data_out = data[i]['OBSERVATIONS'].copy()\n",
        "        if service == 'timeseries':\n",
        "            datetime = pd.to_datetime(data_out['date_time'], format=(dattim_format))\n",
        "            del data_out['date_time']\n",
        "            multi_index = pd.MultiIndex.from_product([[stid], datetime],\n",
        "                                                     names=[\"stid\", \"dattim\"])\n",
        "        else:\n",
        "            datetime = pd.to_datetime(data_out[list(data_out.keys())[0]]['date_time'], format=(dattim_format))\n",
        "            for key in data_out:\n",
        "                data_out.update({key: data_out[key]['value']})\n",
        "            multi_index = pd.MultiIndex.from_arrays([[stid], [datetime]],\n",
        "                                                    names=[\"stid\", \"dattim\"])\n",
        "\n",
        "        #Concatenate as needed\n",
        "        if i == 0:\n",
        "            data_df = pd.DataFrame(data_out, index=multi_index)\n",
        "        else:\n",
        "            data_df = pd.concat([data_df, pd.DataFrame(data_out, index=multi_index)], axis=0)\n",
        "\n",
        "    #Build metadata dataframe from list\n",
        "    meta_df = pd.DataFrame(meta_list, columns=[\"stid\", \"mnet_id\", \"lon\", \"lat\", \"elev\"])\n",
        "    meta_df.set_index('stid', inplace=True)\n",
        "\n",
        "    # Sort the resulting data dataframe by time\n",
        "    data_df.sort_index(inplace=True)\n",
        "\n",
        "    return data_df, meta_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alOiby5Mz_i0"
      },
      "outputs": [],
      "source": [
        "def make_api_request(url, api_args):\n",
        "    \"\"\"Build the api request from the url and api_args, make the request, and parse \n",
        "    the json return to a dictionary\n",
        "\n",
        "    Parameters:\n",
        "        url: str, url of the api endpoint\n",
        "        api_args: dict, api arguments\n",
        "    \n",
        "    Returns:\n",
        "        output: dict, api request response \n",
        "    \"\"\"\n",
        "    # Append the api arguments on to the url\n",
        "    for argument, value in api_args.items():\n",
        "        url = url + '&' + argument + '=' + value\n",
        "\n",
        "    # Make the api request\n",
        "    print(f\"API request: {url}\")\n",
        "    with req.urlopen(url) as response:\n",
        "        body = response.read()\n",
        "\n",
        "    # parse the json response. \n",
        "    try:\n",
        "        output = json.loads(body)\n",
        "    except:\n",
        "        decoded_body = body.decode('latin1')\n",
        "        output = json.loads(decoded_body)\n",
        "\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QSajUNqyhVp"
      },
      "source": [
        "# Step 1: Build and make the API request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDitJNKy1zgt"
      },
      "source": [
        "Let's build the api request we want to make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oACEaQ2rFgf"
      },
      "outputs": [],
      "source": [
        "token = ''\n",
        "url = 'https://api.synopticdata.com/v2/stations/timeseries?'\n",
        "api_args = {'radius': '34.427,-119.159,20',\n",
        "            'start': '201712030000',\n",
        "            'end': '201712050000',\n",
        "            'obtimezone': 'local',\n",
        "            'token': token,\n",
        "            'vars': 'air_temp,wind_gust,wind_speed,relative_humidity'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If2rwnM716Du"
      },
      "source": [
        "Make the request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxNMiNmVr1B2"
      },
      "outputs": [],
      "source": [
        "data = make_api_request(url, api_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owNaDPpF1tSu"
      },
      "source": [
        "# Step 2: Some initial insights into the data return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqB0Db5v2EFA"
      },
      "source": [
        "Let's start by confirming the contents have the keys we reviewed in the Explore exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_JVuPXfsDD-",
        "outputId": "699a5cf4-192c-494f-e179-913e4c92fb0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['UNITS', 'QC_SUMMARY', 'STATION', 'SUMMARY'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwq_34tT95Zr"
      },
      "source": [
        "... we can quickly view the number of objects (stations) have been returned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q0anvXA99gO"
      },
      "outputs": [],
      "source": [
        "# TODO Print the summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEBGr_gxJc1"
      },
      "source": [
        "... and do things like get a glimpse of the units returned for our requested variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOhrRtpRxQtl"
      },
      "outputs": [],
      "source": [
        "# TODO Print the units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaEx3XVY2HL5"
      },
      "source": [
        "Now let's build out the DataFrames for the metadata and data return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m-n7Ym7taYi"
      },
      "outputs": [],
      "source": [
        "data_df, meta_df = return_station_df(data['STATION'], 'timeseries')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnS_uCFJ2nXM"
      },
      "outputs": [],
      "source": [
        "meta_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIbIQLZO7LXF"
      },
      "source": [
        "How many unique networks do these stations encompass?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW39OG0jxyh6"
      },
      "outputs": [],
      "source": [
        "meta_df['mnet_id'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pWNduBTyIao"
      },
      "source": [
        "Alright! Let's take a quick look at the data... timeseries data for each particular station. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t55iN_Svy4XU"
      },
      "outputs": [],
      "source": [
        "data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY3k2O3c7zie"
      },
      "source": [
        "# Q1a: what were peak wind gusts like in the days around the start of the fire?\n",
        "Let's start by checking the max wind gust across stations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goL6xqBSvgUC"
      },
      "outputs": [],
      "source": [
        "max_wind_gust = data_df['wind_gust_set_1'].groupby(level=0).max()\n",
        "max_wind_gust.sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me1bVIIgbDxe"
      },
      "source": [
        "Woah. Some gusts up to 60 mph! \n",
        "\n",
        "Out of curiousity, is there any relationship between the wind gust and station elevation? Did these winds originate at high elevations across the area or might they have been more localized in nature?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VqrHZonZku6"
      },
      "outputs": [],
      "source": [
        "wind_elev = pd.concat([max_wind_gust, meta_df['elev']], axis=1)\n",
        "fig0 = plt.figure(0, figsize=(12,6))\n",
        "ax0 = fig0.add_subplot(111)\n",
        "ax0.plot(wind_elev['elev'], wind_elev['wind_gust_set_1'], 'ko')\n",
        "ax0.set_xlabel(f\"Station Elevation ({data['UNITS']['elevation']})\")\n",
        "ax0.set_ylabel(f\"Max wind gust ({data['UNITS']['wind_gust']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AGGQcfOO0xv"
      },
      "source": [
        "# Q1b: How sustained were winds?\n",
        "\n",
        "Let's take a closer look at the winds of these windiest stations to get better situational awareness of when these started to ramp up.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sYrE80f1ur2"
      },
      "outputs": [],
      "source": [
        "fig1 = plt.figure(1, figsize=(12,6))\n",
        "ax = fig1.add_subplot(111)\n",
        "ax.plot(data_df.loc['WLYC1'].index, data_df.loc['WLYC1','wind_speed_set_1'], 'r-', label='WLYC1')\n",
        "ax.plot(data_df.loc['AT184'].index, data_df.loc['AT184','wind_speed_set_1'], 'k-', label='AT184')\n",
        "ax.plot(data_df.loc['KCMA'].index, data_df.loc['KCMA','wind_speed_set_1'], 'b-', label='KCMA')\n",
        "ax.legend()\n",
        "ax.set_xlabel('Local Date/time')\n",
        "ax.set_ylabel(f\"Wind speed ({data['UNITS']['wind_speed']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8KblUcHPCaT"
      },
      "source": [
        "# Question 2: How might the interaction of wind, RH, and temperature have affected fire conditions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86LaC8QkGe2G"
      },
      "outputs": [],
      "source": [
        "fig2 = plt.figure(2, figsize=(12,6))\n",
        "ax2 = fig2.add_subplot(111)\n",
        "ax2b = ax2.twinx()\n",
        "ax2c = ax2.twinx()\n",
        "\n",
        "#Offset the 3rd axis\n",
        "ax2c.spines['right'].set_position((\"axes\", 1.1))\n",
        "\n",
        "# Plot\n",
        "ax2.plot(data_df.loc['WLYC1'].index, data_df.loc['WLYC1','wind_speed_set_1'], 'b-', label='wind_speed')\n",
        "ax2b.plot(data_df.loc['WLYC1'].index, data_df.loc['WLYC1','relative_humidity_set_1'], 'r-', label='RH')\n",
        "ax2c.plot(data_df.loc['WLYC1'].index, data_df.loc['WLYC1','air_temp_set_1'], 'g-', label='Air temp')\n",
        "\n",
        "ax2.set_ylim(-20,20)\n",
        "ax2b.set_ylim(0,100)\n",
        "\n",
        "# Set axis label colors\n",
        "ax2.tick_params(axis='y', colors='b')\n",
        "ax2b.tick_params(axis='y', colors='r')\n",
        "ax2c.tick_params(axis='y', colors='g')\n",
        "\n",
        "ax2.set_ylabel(f\"wind speed ({data['UNITS']['wind_speed']})\", color='b')\n",
        "ax2b.set_ylabel(f\"RH ({data['UNITS']['relative_humidity']})\", color='r')\n",
        "ax2c.set_ylabel(f\"air temp ({data['UNITS']['air_temp']})\", color='g')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqIzUUY0hsBU"
      },
      "source": [
        "# Question 3: Were these wind & RH values anomalous with respect to the past month?\n",
        "\n",
        "Let's focus in a little more on a station and explore wind and RH over the month leading up to the Thomas Fire. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb7tVLiah03t"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
